{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-ijxti0SiIn"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os , sys ,cv2\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import keras.applications\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new folder to store the snapshots from train videos\n",
    "try:\n",
    "    os.mkdir(\"./output_dir\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "# Create new folder to store the snapshots from test videos\n",
    "try:\n",
    "    os.mkdir(\"./test_output_dir\")\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the snapshots of the training videos for 1/3rd frame of the total length\n",
    "pathOut = \"./output_dir/\"\n",
    "listing = os.listdir(\"./train_video/\")\n",
    "count = 0\n",
    "counter = 1\n",
    "\n",
    "for vid in listing:\n",
    "    vid1 = \"./train_video/\"+vid\n",
    "    cap = cv2.VideoCapture(vid1)\n",
    "    frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) / 3) # Divide by 3 to get correct frame\n",
    "    count = 0\n",
    "    counter += 1\n",
    "    success = True\n",
    "    while success:\n",
    "        success,image = cap.read()\n",
    "        print('read a new frame:',success)\n",
    "        if count == frame:\n",
    "            cv2.imwrite(pathOut + str(vid) + \".jpg\",image)\n",
    "            print (success)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the snapshots of the test videos for 1/3rd frame of the total length\n",
    "pathOut = \"./test_output_dir/\"\n",
    "listing = os.listdir(\"./test_video/\")\n",
    "count = 0\n",
    "counter = 1\n",
    "\n",
    "for vid in listing:\n",
    "    vid1 = \"./test_video/\"+vid\n",
    "    cap = cv2.VideoCapture(vid1)\n",
    "    frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) / 3) # Divide by 3 to get proper frame\n",
    "    count = 0\n",
    "    counter += 1\n",
    "    success = True\n",
    "    while success:\n",
    "        success,image = cap.read()\n",
    "        print('read a new frame:',success)\n",
    "        if count == frame:\n",
    "            cv2.imwrite(pathOut + str(vid) + \".jpg\",image)\n",
    "            print (success)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0Hrd6Qr2Seou",
    "outputId": "88cff61c-9a62-444c-dd3e-f53f36931ed4"
   },
   "outputs": [],
   "source": [
    "# Read the labels for the training images after appending .jpg to the image filename\n",
    "df_train = pd.read_csv('tarin_tag.txt',header=None, sep=',')\n",
    "df_train.columns = ['filename','label']\n",
    "df_train['filename'] = df_train['filename'] + '.jpg'\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_kubYYPUMdr"
   },
   "outputs": [],
   "source": [
    "filename = df_train.filename.values\n",
    "label = df_train.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbaPe8ykeqJv"
   },
   "outputs": [],
   "source": [
    "# Function to get the image size in the image directory\n",
    "def file_size_train(file_name):\n",
    "    stats=os.stat(\"output_dir/\"+str(file_name))\n",
    "    return stats.st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Sq1JBOkUYd_"
   },
   "outputs": [],
   "source": [
    "# Function to call the keras pre-trained model to get feature weights of the train images\n",
    "def resnet_model_train():\n",
    "    n=0\n",
    "    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    images_path = \"./output_dir\"\n",
    "    # Looping over every image present in the files list\n",
    "    for img_path in filename:\n",
    "        if(file_size_train(img_path)!=0):\n",
    "            print(str(img_path))\n",
    "            n+=1\n",
    "            print(n)\n",
    "            # load the image and resize it\n",
    "            img = image.load_img(\"./output_dir/\"+str(img_path), target_size=(224, 224))\n",
    "            # extract features from each image\n",
    "            x_image = image.img_to_array(img)\n",
    "            x_image = np.expand_dims(x_image, axis=0) # increase dimensions of x to make it suitable for further feature extraction\n",
    "            x_image = preprocess_input(x_image)\n",
    "            x_features = model.predict(x_image) # extract image features from model\n",
    "            x_features = np.array(x_features) # convert features list to numpy array\n",
    "            x_flatten= x_features.flatten() # flatten out the features in x\n",
    "            train_features.append(x_flatten) # this list contains the final features of the train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KzoY9-_eU2_W"
   },
   "outputs": [],
   "source": [
    "# Function to get the image size in the image directory\n",
    "def file_size_test(file_name):\n",
    "    stats=os.stat(\"test_output_dir/\"+str(file_name))\n",
    "    return stats.st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kcxP_HbuU6eC"
   },
   "outputs": [],
   "source": [
    "# Function to call the keras pre-trained model to get feature weights of the test images\n",
    "def resnet_model_test():\n",
    "    n=0\n",
    "    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    images_path = \"./test_output_dir\"\n",
    "    for f in os.listdir(images_path):\n",
    "        test_files.append(f)\n",
    "    # Looping over every image present in the files list\n",
    "    for img_path in test_files:\n",
    "        if(file_size_test(img_path)!=0):\n",
    "            print(str(img_path))\n",
    "            n+=1\n",
    "            print(n)\n",
    "            # load the image and resize it\n",
    "            img = image.load_img(\"./test_output_dir/\"+str(img_path), target_size=(224, 224))\n",
    "            # extract features from each image\n",
    "            x_image = image.img_to_array(img)\n",
    "            x_image = np.expand_dims(x_image, axis=0) # increase dimensions of x to make it suitable for further feature extraction\n",
    "            x_image = preprocess_input(x_image)\n",
    "            x_features = model.predict(x_image) # extract image features from model\n",
    "            x_features = np.array(x_features) # convert features list to numpy array\n",
    "            x_flatten= x_features.flatten() # flatten out the features in x\n",
    "            test_features.append(x_flatten) # this list contains the final features of the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70159
    },
    "colab_type": "code",
    "id": "3lKtpdFRY4nb",
    "outputId": "e012a1a3-0f05-4de9-b3c9-a267142ff40e"
   },
   "outputs": [],
   "source": [
    "# Get features for every image extracted from train videos\n",
    "train_features=[]\n",
    "resnet_model_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rkwlp-8FjYf_"
   },
   "outputs": [],
   "source": [
    "# Scale all features with standard scaler\n",
    "ss = StandardScaler()\n",
    "train_features = ss.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 30481
    },
    "colab_type": "code",
    "id": "dNFPEcpqjuCO",
    "outputId": "9b6adb4e-1a2d-4381-d38a-20fd1bae84a9"
   },
   "outputs": [],
   "source": [
    "# Get features for every image extracted from test videos\n",
    "test_features=[]\n",
    "test_files = []\n",
    "resnet_model_test()\n",
    "test_features = ss.transform(test_features) # scale the test video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rbOTkCrjwRE"
   },
   "outputs": [],
   "source": [
    "#Train the model with SVC on extracted features and provided labels\n",
    "model = svm.SVC()\n",
    "model.fit(train_features,label)\n",
    "pred = model.predict(test_features) # predict the labels for test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXu96WuOMdRy"
   },
   "outputs": [],
   "source": [
    "# Strip all .jpg from the end of the filename\n",
    "test_files1 = [s.strip('.jpg') for s in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3txyvpgtupK1"
   },
   "outputs": [],
   "source": [
    "# Write the output in CSV format\n",
    "label_output = pd.DataFrame(pred, columns=['label'])\n",
    "testfile_output = pd.DataFrame(test_files1, columns=['file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dqe3PO2cNCeH"
   },
   "outputs": [],
   "source": [
    "result = pd.concat([testfile_output, label_output], axis=1, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "85tAy6-ANmjy",
    "outputId": "3e5e7df9-b3cb-4c0e-948d-f9f41d1832b3"
   },
   "outputs": [],
   "source": [
    "result.columns=['file_name','label']\n",
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEIBzv5bNjMU"
   },
   "outputs": [],
   "source": [
    "result.to_csv('output.csv', header=True, index=False) # save output in csv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Q6_RNN",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
